# -*- coding: utf-8 -*-
"""Untitled16.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HJnfySBU56BbZ-LFDfqcWxC0l_WTkgeJ
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Ensure reproducibility
np.random.seed(42)
tf.random.set_seed(42)

# Load the dataset (assuming it is in CSV format)
data = pd.read_csv("weather_data.csv")

# Convert Date_Time to datetime and extract useful features
data['Date_Time'] = pd.to_datetime(data['Date_Time'])
data['Year'] = data['Date_Time'].dt.year
data['Month'] = data['Date_Time'].dt.month
data['Day'] = data['Date_Time'].dt.day
data['Hour'] = data['Date_Time'].dt.hour

# Drop the original Date_Time column
data = data.drop(columns=['Date_Time'])

# Encode categorical data (Location)
data = pd.get_dummies(data, columns=['Location'])

# Define features and target variable
X = data.drop(columns=['Temperature_C'])
y = data['Temperature_C']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

model = Sequential([
    Dense(64, input_dim=X_train.shape[1], activation='relu'),
    Dense(32, activation='relu'),
    Dense(16, activation='relu'),
    Dense(1)  # Output layer for regression
])

model.compile(optimizer='adam', loss='mse', metrics=['mae'])

history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)

# Evaluate on the test set
test_loss, test_mae = model.evaluate(X_test, y_test)
print(f'Test MAE: {test_mae}')

# Make predictions on the test set
predictions = model.predict(X_test)

# Optional: Compare the predictions with the actual values
comparison = pd.DataFrame({'Actual': y_test, 'Predicted': predictions.flatten()})
print(comparison.head())

import matplotlib.pyplot as plt

plt.plot(history.history['loss'], label='train_loss')
plt.plot(history.history['val_loss'], label='val_loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

plt.plot(history.history['mae'], label='train_mae')
plt.plot(history.history['val_mae'], label='val_mae')
plt.xlabel('Epochs')
plt.ylabel('Mean Absolute Error')
plt.legend()
plt.show()

import joblib

# Save the trained model
joblib.dump(model, 'weather_model.joblib')

import streamlit as st
import joblib
import numpy as np

# Load the trained model
model = joblib.load('weather_model.joblib')

# Streamlit UI
st.title("üå¶Ô∏è Weather Prediction App")
st.write("Enter weather conditions to predict the temperature.")

# User inputs
humidity = st.number_input("Humidity (%)", min_value=0.0, max_value=100.0)
pressure = st.number_input("Pressure (hPa)", min_value=900.0, max_value=1100.0)
wind_speed = st.number_input("Wind Speed (m/s)", min_value=0.0, max_value=50.0)

# Prediction
if st.button("Predict Temperature"):
    input_data = np.array([[humidity, pressure, wind_speed]])  # Adjust features
    prediction = model.predict(input_data)
    st.success(f"üå°Ô∏è Predicted Temperature: {prediction[0]:.2f}¬∞C")

!pip install streamlit joblib scikit-learn numpy pandas

!streamlit run app.py
