# -*- coding: utf-8 -*-
"""Untitled16.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HJnfySBU56BbZ-LFDfqcWxC0l_WTkgeJ
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Ensure reproducibility
np.random.seed(42)
tf.random.set_seed(42)

# Load the dataset (assuming it is in CSV format)
data = pd.read_csv("weather_data.csv")

# Convert Date_Time to datetime and extract useful features
data['Date_Time'] = pd.to_datetime(data['Date_Time'])
data['Year'] = data['Date_Time'].dt.year
data['Month'] = data['Date_Time'].dt.month
data['Day'] = data['Date_Time'].dt.day
data['Hour'] = data['Date_Time'].dt.hour

# Drop the original Date_Time column
data = data.drop(columns=['Date_Time'])

# Encode categorical data (Location)
data = pd.get_dummies(data, columns=['Location'])

# Define features and target variable
X = data.drop(columns=['Temperature_C'])
y = data['Temperature_C']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

model = Sequential([
    Dense(64, input_dim=X_train.shape[1], activation='relu'),
    Dense(32, activation='relu'),
    Dense(16, activation='relu'),
    Dense(1)  # Output layer for regression
])

model.compile(optimizer='adam', loss='mse', metrics=['mae'])

history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)

# Evaluate on the test set
test_loss, test_mae = model.evaluate(X_test, y_test)
print(f'Test MAE: {test_mae}')

# Make predictions on the test set
predictions = model.predict(X_test)

# Optional: Compare the predictions with the actual values
comparison = pd.DataFrame({'Actual': y_test, 'Predicted': predictions.flatten()})
print(comparison.head())

import matplotlib.pyplot as plt

plt.plot(history.history['loss'], label='train_loss')
plt.plot(history.history['val_loss'], label='val_loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

plt.plot(history.history['mae'], label='train_mae')
plt.plot(history.history['val_mae'], label='val_mae')
plt.xlabel('Epochs')
plt.ylabel('Mean Absolute Error')
plt.legend()
plt.show()

import joblib
joblib.dump(model, "weather_model.pkl")

model.save("weather_model.h5")

from flask import Flask, request, jsonify
import joblib
import numpy as np

app = Flask(__name__)
model = joblib.load("weather_model.pkl")

@app.route('/predict', methods=['POST'])
def predict():
    data = request.json  # Receive JSON input
    features = np.array(data['features']).reshape(1, -1)  # Convert to numpy array
    prediction = model.predict(features)[0]  # Make prediction
    return jsonify({'prediction': prediction})

if __name__ == '__main__':
    app.run(debug=True)

!pip install streamlit

import streamlit as st
import joblib

# Load the trained model
model = joblib.load("weather_model.pkl")

st.title("Weather Prediction App")

temperature = st.number_input("Enter Temperature (Â°C):")
humidity = st.number_input("Enter Humidity (%):")
pressure = st.number_input("Enter Pressure (hPa):")

if st.button("Predict"):
    features = [[temperature, humidity, pressure]]
    prediction = model.predict(features)
    st.write(f"Predicted Weather Condition: {prediction}")

!python app.py

!pip install joblib

!streamlit run app.py


